{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8437c88",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603c48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1528e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating random data having Linear relationships \n",
    "np.random.seed(50)\n",
    "\n",
    "sales = 2*np.random.randn(50) + 50\n",
    "advertising = 20*sales+3+np.random.randint(10,40, size = len(sales))\n",
    "\n",
    "data = np.array([sales, advertising])\n",
    "data = pd.DataFrame(data = data.T, columns = ['sales', 'advertising'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bde27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>advertising</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.879296</td>\n",
       "      <td>961.585916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.938045</td>\n",
       "      <td>1014.760896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.758143</td>\n",
       "      <td>994.162863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.070839</td>\n",
       "      <td>981.416781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.823892</td>\n",
       "      <td>1087.477845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49.046536</td>\n",
       "      <td>1019.930714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48.439062</td>\n",
       "      <td>1005.781231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52.140535</td>\n",
       "      <td>1083.810709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47.435415</td>\n",
       "      <td>969.708296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47.345042</td>\n",
       "      <td>974.900844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50.252675</td>\n",
       "      <td>1023.053506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>51.724387</td>\n",
       "      <td>1073.487749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>51.393474</td>\n",
       "      <td>1060.869479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>49.330870</td>\n",
       "      <td>1022.617393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>48.004948</td>\n",
       "      <td>1002.098957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53.197817</td>\n",
       "      <td>1100.956332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>56.628151</td>\n",
       "      <td>1160.563014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51.975541</td>\n",
       "      <td>1056.510818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50.247733</td>\n",
       "      <td>1021.954650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>51.485571</td>\n",
       "      <td>1060.711416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>49.212088</td>\n",
       "      <td>1012.241766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50.296232</td>\n",
       "      <td>1028.924633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>49.175531</td>\n",
       "      <td>1013.510622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>49.678570</td>\n",
       "      <td>1032.571398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50.279063</td>\n",
       "      <td>1026.581259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50.570939</td>\n",
       "      <td>1038.418775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>49.437476</td>\n",
       "      <td>1012.749520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>53.421815</td>\n",
       "      <td>1108.436293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>49.700467</td>\n",
       "      <td>1034.009334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>51.380613</td>\n",
       "      <td>1067.612269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>52.190419</td>\n",
       "      <td>1063.808380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>52.676817</td>\n",
       "      <td>1075.536348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>47.262037</td>\n",
       "      <td>959.240733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50.972855</td>\n",
       "      <td>1053.457105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>51.507043</td>\n",
       "      <td>1051.140867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>50.726929</td>\n",
       "      <td>1030.538584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>49.370579</td>\n",
       "      <td>1003.411581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>52.746562</td>\n",
       "      <td>1088.931247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>48.751166</td>\n",
       "      <td>998.023313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>50.751508</td>\n",
       "      <td>1031.030160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>49.599167</td>\n",
       "      <td>1010.983347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>51.486076</td>\n",
       "      <td>1066.721522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>51.714724</td>\n",
       "      <td>1062.294478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>46.987621</td>\n",
       "      <td>974.752429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>46.667296</td>\n",
       "      <td>946.345913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>49.562010</td>\n",
       "      <td>1028.240208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>49.282283</td>\n",
       "      <td>1016.645663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>50.757055</td>\n",
       "      <td>1054.141108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>51.368431</td>\n",
       "      <td>1051.368615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>47.664288</td>\n",
       "      <td>967.285757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sales  advertising\n",
       "0   46.879296   961.585916\n",
       "1   49.938045  1014.760896\n",
       "2   48.758143   994.162863\n",
       "3   47.070839   981.416781\n",
       "4   52.823892  1087.477845\n",
       "5   49.046536  1019.930714\n",
       "6   48.439062  1005.781231\n",
       "7   52.140535  1083.810709\n",
       "8   47.435415   969.708296\n",
       "9   47.345042   974.900844\n",
       "10  50.252675  1023.053506\n",
       "11  51.724387  1073.487749\n",
       "12  51.393474  1060.869479\n",
       "13  49.330870  1022.617393\n",
       "14  48.004948  1002.098957\n",
       "15  53.197817  1100.956332\n",
       "16  56.628151  1160.563014\n",
       "17  51.975541  1056.510818\n",
       "18  50.247733  1021.954650\n",
       "19  51.485571  1060.711416\n",
       "20  49.212088  1012.241766\n",
       "21  50.296232  1028.924633\n",
       "22  49.175531  1013.510622\n",
       "23  49.678570  1032.571398\n",
       "24  50.279063  1026.581259\n",
       "25  50.570939  1038.418775\n",
       "26  49.437476  1012.749520\n",
       "27  53.421815  1108.436293\n",
       "28  49.700467  1034.009334\n",
       "29  51.380613  1067.612269\n",
       "30  52.190419  1063.808380\n",
       "31  52.676817  1075.536348\n",
       "32  47.262037   959.240733\n",
       "33  50.972855  1053.457105\n",
       "34  51.507043  1051.140867\n",
       "35  50.726929  1030.538584\n",
       "36  49.370579  1003.411581\n",
       "37  52.746562  1088.931247\n",
       "38  48.751166   998.023313\n",
       "39  50.751508  1031.030160\n",
       "40  49.599167  1010.983347\n",
       "41  51.486076  1066.721522\n",
       "42  51.714724  1062.294478\n",
       "43  46.987621   974.752429\n",
       "44  46.667296   946.345913\n",
       "45  49.562010  1028.240208\n",
       "46  49.282283  1016.645663\n",
       "47  50.757055  1054.141108\n",
       "48  51.368431  1051.368615\n",
       "49  47.664288   967.285757"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8844a165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c7049dbac0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data['sales'], data['advertising'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e73068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the regression coefficients\n",
    "\n",
    "coeff_a = sum(advertising*(sales - np.mean(sales))) / sum((sales-np.mean(sales))**2)\n",
    "coeff_b = np.mean(advertising) - coeff_a * np.mean(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aac5070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression coefficients are :  20.76275886890265 -10.300055059918577\n"
     ]
    }
   ],
   "source": [
    "print(\"The regression coefficients are : \", coeff_a, coeff_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987c37b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c704be28e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predicting the data \n",
    "y_pred = coeff_a * sales + coeff_b\n",
    "plt.plot(sales, y_pred, color = 'red', label = 'Predicting Sales')\n",
    "plt.scatter(data['sales'], data['advertising'], label = 'Training Data')\n",
    "plt.xlabel('sales')\n",
    "plt.ylabel('advertising')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899db230",
   "metadata": {},
   "source": [
    "# Predicting House Price using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4789164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 489 entries, 0 to 488\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   RM       489 non-null    float64\n",
      " 1   LSTAT    489 non-null    float64\n",
      " 2   PTRATIO  489 non-null    float64\n",
      " 3   MEDV     489 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 15.4 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/antra0497/Udacity-Predicting-Boston-Housing-Prices/master/housing.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28d53d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('MEDV', axis = 1) # define independent predictor set (excluding the dependent variable)\n",
    "y = df['MEDV'] # define the target values (i.e. the dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94191624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327, 3)\n",
      "(327,)\n",
      "(162, 3)\n",
      "(162,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 5)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d1238d",
   "metadata": {},
   "source": [
    "# Basic Linear Regression\n",
    "In linear regression we assume that the relationship between the independent variables (X) and the dependent variable (Y) is linear and then go about finding one that minimizes the squared error between the predicted Y and the actual Y.\n",
    "\n",
    "                                                    yi=β0+β1xi+ϵi\n",
    " \n",
    "We now import the LinearRegression method from the sklearn library. Note that the process of creating the model involves the very simple command lm.fit(X,Y). This runs the model and we find the intercept-term,  β0 , and the coefficient  β1  that minimizes the squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90bf0e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train, y_train)\n",
    "y_pred_train = lm.predict(x_train)\n",
    "y_pred = lm.predict(x_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Price : $Y_i$\")\n",
    "plt.ylabel(\"Predicted Price : $\\hat{Y}_i$\")\n",
    "plt.title(\"Predicted Price Vs Actual Price : \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca06a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept Term :  505133.9949769226\n",
      "Coefficients :  [ 77880.11980519 -11070.7718746  -21000.37109466]\n"
     ]
    }
   ],
   "source": [
    "# Coefficient\n",
    "\n",
    "print(\"Intercept Term : \", lm.intercept_)\n",
    "print(\"Coefficients : \", lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "455ac57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error :  7068706653.230068\n",
      "Mean Absolute Error :  64577.672957157796\n",
      "R-Square, Training :  0.6993419964520498\n",
      "R-Square, Test :  0.746591067836508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error : \", mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error : \", mae)\n",
    "rsq = r2_score(y_train, y_pred_train) # On training data\n",
    "print(\"R-Square, Training : \", rsq)\n",
    "rsq = r2_score(y_test, y_pred) # on test data \n",
    "print(\"R-Square, Test : \", rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d81de",
   "metadata": {},
   "source": [
    "\n",
    "# Boston House Price Prediction using Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76901490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3de6ed4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
      "        4.9800e+00],\n",
      "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
      "        9.1400e+00],\n",
      "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
      "        4.0300e+00],\n",
      "       ...,\n",
      "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
      "        5.6400e+00],\n",
      "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
      "        6.4800e+00],\n",
      "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
      "        7.8800e+00]]), 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
      "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
      "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
      "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
      "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
      "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
      "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
      "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
      "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
      "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
      "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
      "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
      "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
      "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
      "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
      "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
      "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
      "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
      "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
      "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
      "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
      "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
      "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
      "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
      "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
      "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
      "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
      "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
      "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
      "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
      "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
      "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
      "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
      "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
      "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
      "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
      "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
      "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
      "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
      "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
      "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
      "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
      "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
      "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
      "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
      "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]), 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
      "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'), 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\", 'filename': 'boston_house_prices.csv', 'data_module': 'sklearn.datasets.data'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kushal Raj Sharma\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "housing = load_boston()\n",
    "\n",
    "# Print out the Dataset\n",
    "print(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7249d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN INDUS CHAS    NOX     RM   AGE     DIS  RAD    TAX PTRATIO  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0    15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0    17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0    17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0    18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0    18.7   \n",
       "\n",
       "        B LSTAT  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  5.33  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate Data into Features and Labels\n",
    "# Features\n",
    "features_df = pd.DataFrame(np.array(housing.data), columns=[housing.feature_names])\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c91ac556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e655fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "\n",
       "              DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621  \n",
       "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  \n",
       "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800  \n",
       "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  \n",
       "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879  \n",
       "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  \n",
       "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339  \n",
       "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  \n",
       "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676  \n",
       "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993  \n",
       "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044  \n",
       "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  \n",
       "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d8e01c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels\n",
       "0    24.0\n",
       "1    21.6\n",
       "2    34.7\n",
       "3    33.4\n",
       "4    36.2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "labels_df = pd.DataFrame(np.array(housing.target), columns=['labels'])\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9aab8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features_df), type(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "add9c235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a46a418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e73e4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   (CRIM,)     506 non-null    float64\n",
      " 1   (ZN,)       506 non-null    float64\n",
      " 2   (INDUS,)    506 non-null    float64\n",
      " 3   (CHAS,)     506 non-null    float64\n",
      " 4   (NOX,)      506 non-null    float64\n",
      " 5   (RM,)       506 non-null    float64\n",
      " 6   (AGE,)      506 non-null    float64\n",
      " 7   (DIS,)      506 non-null    float64\n",
      " 8   (RAD,)      506 non-null    float64\n",
      " 9   (TAX,)      506 non-null    float64\n",
      " 10  (PTRATIO,)  506 non-null    float64\n",
      " 11  (B,)        506 non-null    float64\n",
      " 12  (LSTAT,)    506 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f06c0fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   labels  506 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 4.1 KB\n"
     ]
    }
   ],
   "source": [
    "labels_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacd28f0",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2af91506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_df, labels_df, test_size = 0.3, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aad22f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8657d552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dba7982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2f9de99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3fc73",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b59ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2836bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kushal Raj Sharma\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Preprocessing Method and Fit Training Data to it\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ced65a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kushal Raj Sharma\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Make X_train to be the Scaled Version of Data\n",
    "# This process scales all the values in all 6 columns and replaces them with the new values\n",
    "x_train = pd.DataFrame(data=scaler.transform(x_train), columns=x_train.columns, index=x_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3cacca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.875509</td>\n",
       "      <td>-0.499618</td>\n",
       "      <td>1.069608</td>\n",
       "      <td>-0.251124</td>\n",
       "      <td>1.645428</td>\n",
       "      <td>0.233772</td>\n",
       "      <td>0.969882</td>\n",
       "      <td>-0.900522</td>\n",
       "      <td>1.654486</td>\n",
       "      <td>1.538813</td>\n",
       "      <td>0.810913</td>\n",
       "      <td>-3.463820</td>\n",
       "      <td>1.611369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.474665</td>\n",
       "      <td>-0.499618</td>\n",
       "      <td>1.069608</td>\n",
       "      <td>-0.251124</td>\n",
       "      <td>1.113435</td>\n",
       "      <td>-0.149715</td>\n",
       "      <td>0.383159</td>\n",
       "      <td>-0.926152</td>\n",
       "      <td>1.654486</td>\n",
       "      <td>1.538813</td>\n",
       "      <td>0.810913</td>\n",
       "      <td>-2.872888</td>\n",
       "      <td>1.265636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.273444</td>\n",
       "      <td>-0.499618</td>\n",
       "      <td>1.069608</td>\n",
       "      <td>-0.251124</td>\n",
       "      <td>-0.168580</td>\n",
       "      <td>0.653301</td>\n",
       "      <td>0.270733</td>\n",
       "      <td>-0.241993</td>\n",
       "      <td>1.654486</td>\n",
       "      <td>1.538813</td>\n",
       "      <td>0.810913</td>\n",
       "      <td>0.389957</td>\n",
       "      <td>-0.671032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>3.445319</td>\n",
       "      <td>-1.442682</td>\n",
       "      <td>-0.251124</td>\n",
       "      <td>-1.293614</td>\n",
       "      <td>1.372699</td>\n",
       "      <td>-1.591321</td>\n",
       "      <td>2.387078</td>\n",
       "      <td>-0.527917</td>\n",
       "      <td>-1.061095</td>\n",
       "      <td>-0.265106</td>\n",
       "      <td>0.421447</td>\n",
       "      <td>-1.082820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>-0.400634</td>\n",
       "      <td>-0.499618</td>\n",
       "      <td>2.504352</td>\n",
       "      <td>-0.251124</td>\n",
       "      <td>0.502952</td>\n",
       "      <td>-1.215116</td>\n",
       "      <td>0.896102</td>\n",
       "      <td>-0.982361</td>\n",
       "      <td>-0.642780</td>\n",
       "      <td>1.804713</td>\n",
       "      <td>0.764129</td>\n",
       "      <td>0.412198</td>\n",
       "      <td>0.779361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.271452</td>\n",
       "      <td>-0.499618</td>\n",
       "      <td>1.069608</td>\n",
       "      <td>-0.251124</td>\n",
       "      <td>0.276201</td>\n",
       "      <td>-0.263608</td>\n",
       "      <td>0.442885</td>\n",
       "      <td>-0.137024</td>\n",
       "      <td>1.654486</td>\n",
       "      <td>1.538813</td>\n",
       "      <td>0.810913</td>\n",
       "      <td>0.385663</td>\n",
       "      <td>0.346492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-0.408780</td>\n",
       "      <td>1.472851</td>\n",
       "      <td>-1.112274</td>\n",
       "      <td>-0.251124</td>\n",
       "      <td>-0.997094</td>\n",
       "      <td>1.280432</td>\n",
       "      <td>-0.994058</td>\n",
       "      <td>0.363219</td>\n",
       "      <td>-0.527917</td>\n",
       "      <td>-0.044767</td>\n",
       "      <td>-1.528259</td>\n",
       "      <td>0.432127</td>\n",
       "      <td>-1.001306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-0.397222</td>\n",
       "      <td>-0.499618</td>\n",
       "      <td>-0.182072</td>\n",
       "      <td>-0.251124</td>\n",
       "      <td>0.293643</td>\n",
       "      <td>-0.903713</td>\n",
       "      <td>-1.348902</td>\n",
       "      <td>-0.503239</td>\n",
       "      <td>-0.413054</td>\n",
       "      <td>-0.086129</td>\n",
       "      <td>0.343078</td>\n",
       "      <td>0.392379</td>\n",
       "      <td>0.714712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-0.391072</td>\n",
       "      <td>-0.499618</td>\n",
       "      <td>-0.048122</td>\n",
       "      <td>-0.251124</td>\n",
       "      <td>-0.543592</td>\n",
       "      <td>0.042029</td>\n",
       "      <td>-0.516248</td>\n",
       "      <td>0.259426</td>\n",
       "      <td>-0.642780</td>\n",
       "      <td>-0.759742</td>\n",
       "      <td>0.062378</td>\n",
       "      <td>0.409776</td>\n",
       "      <td>-0.217082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-0.406003</td>\n",
       "      <td>3.006992</td>\n",
       "      <td>-1.339987</td>\n",
       "      <td>-0.251124</td>\n",
       "      <td>-1.206402</td>\n",
       "      <td>-0.520227</td>\n",
       "      <td>-1.675640</td>\n",
       "      <td>3.312831</td>\n",
       "      <td>-0.642780</td>\n",
       "      <td>-0.422936</td>\n",
       "      <td>1.653014</td>\n",
       "      <td>0.202448</td>\n",
       "      <td>-0.976008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "445  0.875509 -0.499618  1.069608 -0.251124  1.645428  0.233772  0.969882   \n",
       "428  0.474665 -0.499618  1.069608 -0.251124  1.113435 -0.149715  0.383159   \n",
       "481  0.273444 -0.499618  1.069608 -0.251124 -0.168580  0.653301  0.270733   \n",
       "55  -0.417342  3.445319 -1.442682 -0.251124 -1.293614  1.372699 -1.591321   \n",
       "488 -0.400634 -0.499618  2.504352 -0.251124  0.502952 -1.215116  0.896102   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "486  0.271452 -0.499618  1.069608 -0.251124  0.276201 -0.263608  0.442885   \n",
       "189 -0.408780  1.472851 -1.112274 -0.251124 -0.997094  1.280432 -0.994058   \n",
       "495 -0.397222 -0.499618 -0.182072 -0.251124  0.293643 -0.903713 -1.348902   \n",
       "206 -0.391072 -0.499618 -0.048122 -0.251124 -0.543592  0.042029 -0.516248   \n",
       "355 -0.406003  3.006992 -1.339987 -0.251124 -1.206402 -0.520227 -1.675640   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "445 -0.900522  1.654486  1.538813  0.810913 -3.463820  1.611369  \n",
       "428 -0.926152  1.654486  1.538813  0.810913 -2.872888  1.265636  \n",
       "481 -0.241993  1.654486  1.538813  0.810913  0.389957 -0.671032  \n",
       "55   2.387078 -0.527917 -1.061095 -0.265106  0.421447 -1.082820  \n",
       "488 -0.982361 -0.642780  1.804713  0.764129  0.412198  0.779361  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "486 -0.137024  1.654486  1.538813  0.810913  0.385663  0.346492  \n",
       "189  0.363219 -0.527917 -0.044767 -1.528259  0.432127 -1.001306  \n",
       "495 -0.503239 -0.413054 -0.086129  0.343078  0.392379  0.714712  \n",
       "206  0.259426 -0.642780 -0.759742  0.062378  0.409776 -0.217082  \n",
       "355  3.312831 -0.642780 -0.422936  1.653014  0.202448 -0.976008  \n",
       "\n",
       "[354 rows x 13 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77424e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert pandas  dataframe to numpy array \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0335f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check whether it is converted into numpy or not\n",
    "type(x_train), type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7743ca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kushal Raj Sharma\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply same Normalization for Test Features\n",
    "scal = StandardScaler()\n",
    "scal.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "575a1965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kushal Raj Sharma\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Make X_test to be the Scaled Version of Data\n",
    "# This process scales all the values in all columns and replaces them with the new values\n",
    "x_test = pd.DataFrame(data=scal.transform(x_test), columns=x_test.columns, index=x_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0748824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>-0.385617</td>\n",
       "      <td>-0.462563</td>\n",
       "      <td>-0.765365</td>\n",
       "      <td>-0.318511</td>\n",
       "      <td>-0.496400</td>\n",
       "      <td>2.477336</td>\n",
       "      <td>0.544070</td>\n",
       "      <td>-0.226759</td>\n",
       "      <td>-0.165979</td>\n",
       "      <td>-0.646530</td>\n",
       "      <td>-0.463706</td>\n",
       "      <td>0.358359</td>\n",
       "      <td>-1.373735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>-0.422644</td>\n",
       "      <td>2.817184</td>\n",
       "      <td>-0.940677</td>\n",
       "      <td>-0.318511</td>\n",
       "      <td>-1.285114</td>\n",
       "      <td>0.519142</td>\n",
       "      <td>-1.789897</td>\n",
       "      <td>0.621166</td>\n",
       "      <td>-0.626780</td>\n",
       "      <td>-1.019641</td>\n",
       "      <td>0.346964</td>\n",
       "      <td>0.461784</td>\n",
       "      <td>-1.154674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-0.421500</td>\n",
       "      <td>-0.462563</td>\n",
       "      <td>-1.156662</td>\n",
       "      <td>-0.318511</td>\n",
       "      <td>-0.623612</td>\n",
       "      <td>0.223330</td>\n",
       "      <td>-0.210493</td>\n",
       "      <td>-0.281800</td>\n",
       "      <td>-0.857181</td>\n",
       "      <td>-0.869193</td>\n",
       "      <td>-0.283557</td>\n",
       "      <td>0.410506</td>\n",
       "      <td>-0.581211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.762239</td>\n",
       "      <td>-0.462563</td>\n",
       "      <td>0.903603</td>\n",
       "      <td>-0.318511</td>\n",
       "      <td>0.894451</td>\n",
       "      <td>-1.875131</td>\n",
       "      <td>1.043413</td>\n",
       "      <td>-1.137352</td>\n",
       "      <td>1.677224</td>\n",
       "      <td>1.513902</td>\n",
       "      <td>0.797337</td>\n",
       "      <td>0.461784</td>\n",
       "      <td>3.040957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>-0.402767</td>\n",
       "      <td>0.357374</td>\n",
       "      <td>-0.658776</td>\n",
       "      <td>3.139609</td>\n",
       "      <td>-0.835632</td>\n",
       "      <td>1.992648</td>\n",
       "      <td>-0.739427</td>\n",
       "      <td>0.286546</td>\n",
       "      <td>-0.741980</td>\n",
       "      <td>-1.152035</td>\n",
       "      <td>0.076741</td>\n",
       "      <td>0.395188</td>\n",
       "      <td>-0.892360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.410532</td>\n",
       "      <td>0.562358</td>\n",
       "      <td>-0.915432</td>\n",
       "      <td>-0.318511</td>\n",
       "      <td>-0.928921</td>\n",
       "      <td>-0.715492</td>\n",
       "      <td>-0.206794</td>\n",
       "      <td>1.561733</td>\n",
       "      <td>-0.165979</td>\n",
       "      <td>-0.784942</td>\n",
       "      <td>0.572151</td>\n",
       "      <td>0.442337</td>\n",
       "      <td>0.024344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-0.412812</td>\n",
       "      <td>-0.462563</td>\n",
       "      <td>-0.434377</td>\n",
       "      <td>-0.318511</td>\n",
       "      <td>-0.360707</td>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.936147</td>\n",
       "      <td>-0.575920</td>\n",
       "      <td>-0.511580</td>\n",
       "      <td>-0.183151</td>\n",
       "      <td>1.112597</td>\n",
       "      <td>0.443750</td>\n",
       "      <td>-0.098441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-0.419592</td>\n",
       "      <td>2.407215</td>\n",
       "      <td>-1.320753</td>\n",
       "      <td>-0.318511</td>\n",
       "      <td>-1.378403</td>\n",
       "      <td>0.123337</td>\n",
       "      <td>-1.911958</td>\n",
       "      <td>1.830429</td>\n",
       "      <td>-0.511580</td>\n",
       "      <td>-0.339616</td>\n",
       "      <td>-1.634674</td>\n",
       "      <td>0.150424</td>\n",
       "      <td>-1.117002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-0.399779</td>\n",
       "      <td>-0.462563</td>\n",
       "      <td>1.435149</td>\n",
       "      <td>-0.318511</td>\n",
       "      <td>0.521296</td>\n",
       "      <td>-0.554392</td>\n",
       "      <td>0.976834</td>\n",
       "      <td>-0.916829</td>\n",
       "      <td>-0.626780</td>\n",
       "      <td>0.135799</td>\n",
       "      <td>1.247709</td>\n",
       "      <td>0.408985</td>\n",
       "      <td>1.164294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.273244</td>\n",
       "      <td>-0.462563</td>\n",
       "      <td>0.903603</td>\n",
       "      <td>3.139609</td>\n",
       "      <td>0.580661</td>\n",
       "      <td>1.055215</td>\n",
       "      <td>0.950942</td>\n",
       "      <td>-1.124774</td>\n",
       "      <td>1.677224</td>\n",
       "      <td>1.513902</td>\n",
       "      <td>0.797337</td>\n",
       "      <td>0.409094</td>\n",
       "      <td>-1.397454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "226 -0.385617 -0.462563 -0.765365 -0.318511 -0.496400  2.477336  0.544070   \n",
       "292 -0.422644  2.817184 -0.940677 -0.318511 -1.285114  0.519142 -1.789897   \n",
       "90  -0.421500 -0.462563 -1.156662 -0.318511 -0.623612  0.223330 -0.210493   \n",
       "373  0.762239 -0.462563  0.903603 -0.318511  0.894451 -1.875131  1.043413   \n",
       "273 -0.402767  0.357374 -0.658776  3.139609 -0.835632  1.992648 -0.739427   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "60  -0.410532  0.562358 -0.915432 -0.318511 -0.928921 -0.715492 -0.206794   \n",
       "108 -0.412812 -0.462563 -0.434377 -0.318511 -0.360707  0.302491  0.936147   \n",
       "298 -0.419592  2.407215 -1.320753 -0.318511 -1.378403  0.123337 -1.911958   \n",
       "138 -0.399779 -0.462563  1.435149 -0.318511  0.521296 -0.554392  0.976834   \n",
       "370  0.273244 -0.462563  0.903603  3.139609  0.580661  1.055215  0.950942   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "226 -0.226759 -0.165979 -0.646530 -0.463706  0.358359 -1.373735  \n",
       "292  0.621166 -0.626780 -1.019641  0.346964  0.461784 -1.154674  \n",
       "90  -0.281800 -0.857181 -0.869193 -0.283557  0.410506 -0.581211  \n",
       "373 -1.137352  1.677224  1.513902  0.797337  0.461784  3.040957  \n",
       "273  0.286546 -0.741980 -1.152035  0.076741  0.395188 -0.892360  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "60   1.561733 -0.165979 -0.784942  0.572151  0.442337  0.024344  \n",
       "108 -0.575920 -0.511580 -0.183151  1.112597  0.443750 -0.098441  \n",
       "298  1.830429 -0.511580 -0.339616 -1.634674  0.150424 -1.117002  \n",
       "138 -0.916829 -0.626780  0.135799  1.247709  0.408985  1.164294  \n",
       "370 -1.124774  1.677224  1.513902  0.797337  0.409094 -1.397454  \n",
       "\n",
       "[152 rows x 13 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c94fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc2e6671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e7c5b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 152 354 152\n"
     ]
    }
   ],
   "source": [
    "print (len(x_train),len(x_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1880aa5",
   "metadata": {},
   "source": [
    "# Define Feature Columns for Linear Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb2e1073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(   'CRIM',),\n",
       "            (     'ZN',),\n",
       "            (  'INDUS',),\n",
       "            (   'CHAS',),\n",
       "            (    'NOX',),\n",
       "            (     'RM',),\n",
       "            (    'AGE',),\n",
       "            (    'DIS',),\n",
       "            (    'RAD',),\n",
       "            (    'TAX',),\n",
       "            ('PTRATIO',),\n",
       "            (      'B',),\n",
       "            (  'LSTAT',)],\n",
       "           )"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3568056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make feature columns \n",
    "feat_cols = [tf.feature_column.numeric_column('x', shape=np.array(x_train).shape[1:])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d74cb65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kushal Raj Sharma\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KUSHAL~1\\AppData\\Local\\Temp/ipykernel_17256/3205601765.py:2: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Making input functions\n",
    "input_func = tf.compat.v1.estimator.inputs.numpy_input_fn({'x':x_train}, y_train, batch_size=1, num_epochs=2000, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58d05327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\KUSHAL~1\\AppData\\Local\\Temp\\tmpbetxdlj8\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\KUSHAL~1\\\\AppData\\\\Local\\\\Temp\\\\tmpbetxdlj8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Linear Regressor Model\n",
    "linear_model = tf.estimator.LinearRegressor(feature_columns=feat_cols, optimizer='Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8879117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Estimator Training Inputs\n",
    "train_input_func = tf.compat.v1.estimator.inputs.numpy_input_fn(x_train, y_train, batch_size = 1, num_epochs = 1000, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8de92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Estimator Testing Inputs\n",
    "eval_input_func = tf.compat.v1.estimator.inputs.numpy_input_fn({'x' : x_test}, y_test, batch_size = 1, num_epochs = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c3afb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\KUSHAL~1\\AppData\\Local\\Temp\\tmpbetxdlj8\\model.ckpt-2000\n",
      "WARNING:tensorflow:From C:\\Users\\Kushal Raj Sharma\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\KUSHAL~1\\AppData\\Local\\Temp\\tmpbetxdlj8\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
      "INFO:tensorflow:loss = 0.12093384, step = 2000\n",
      "INFO:tensorflow:global_step/sec: 785.096\n",
      "INFO:tensorflow:loss = 0.113826185, step = 2100 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.042\n",
      "INFO:tensorflow:loss = 5.005652, step = 2200 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 895.245\n",
      "INFO:tensorflow:loss = 22.67898, step = 2300 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 871.897\n",
      "INFO:tensorflow:loss = 24.002913, step = 2400 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 911.518\n",
      "INFO:tensorflow:loss = 0.19562156, step = 2500 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 1023.14\n",
      "INFO:tensorflow:loss = 3.3916678, step = 2600 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1033.69\n",
      "INFO:tensorflow:loss = 2.0368953, step = 2700 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 895.247\n",
      "INFO:tensorflow:loss = 45.645065, step = 2800 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 795.779\n",
      "INFO:tensorflow:loss = 1.3186809, step = 2900 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 964.101\n",
      "INFO:tensorflow:loss = 24.889763, step = 3000 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1066.67\n",
      "INFO:tensorflow:loss = 7.071008, step = 3100 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1237.89\n",
      "INFO:tensorflow:loss = 69.39422, step = 3200 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 1089.86\n",
      "INFO:tensorflow:loss = 4.4370956, step = 3300 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1044.45\n",
      "INFO:tensorflow:loss = 16.853731, step = 3400 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 928.403\n",
      "INFO:tensorflow:loss = 30.97924, step = 3500 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1012.79\n",
      "INFO:tensorflow:loss = 0.662129, step = 3600 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1023.15\n",
      "INFO:tensorflow:loss = 7.018091, step = 3700 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 849.722\n",
      "INFO:tensorflow:loss = 12.444737, step = 3800 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 928.414\n",
      "INFO:tensorflow:loss = 20.004961, step = 3900 (0.108 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4000...\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\KUSHAL~1\\AppData\\Local\\Temp\\tmpbetxdlj8\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4000...\n",
      "INFO:tensorflow:Loss for final step: 0.7765283.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x1c704c32be0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Linear regressor estimator\n",
    "linear_model.train(input_fn = input_func, steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59f6c7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-02-10T12:54:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\KUSHAL~1\\AppData\\Local\\Temp\\tmpbetxdlj8\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.29155s\n",
      "INFO:tensorflow:Finished evaluation at 2022-02-10-12:54:22\n",
      "INFO:tensorflow:Saving dict for global step 4000: average_loss = 37.33919, global_step = 4000, label/mean = 22.47829, loss = 37.33919, prediction/mean = 22.748758\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: C:\\Users\\KUSHAL~1\\AppData\\Local\\Temp\\tmpbetxdlj8\\model.ckpt-4000\n"
     ]
    }
   ],
   "source": [
    "test_metrics = linear_model.evaluate(input_fn = eval_input_func, steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "383078b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\KUSHAL~1\\AppData\\Local\\Temp\\tmpbetxdlj8\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'predictions': array([40.68284], dtype=float32)},\n",
       " {'predictions': array([31.554699], dtype=float32)},\n",
       " {'predictions': array([28.544626], dtype=float32)},\n",
       " {'predictions': array([4.8447056], dtype=float32)},\n",
       " {'predictions': array([35.71012], dtype=float32)},\n",
       " {'predictions': array([2.7373486], dtype=float32)},\n",
       " {'predictions': array([27.648514], dtype=float32)},\n",
       " {'predictions': array([31.919151], dtype=float32)},\n",
       " {'predictions': array([28.238222], dtype=float32)},\n",
       " {'predictions': array([24.0307], dtype=float32)},\n",
       " {'predictions': array([34.662785], dtype=float32)},\n",
       " {'predictions': array([22.980503], dtype=float32)},\n",
       " {'predictions': array([24.163229], dtype=float32)},\n",
       " {'predictions': array([35.480255], dtype=float32)},\n",
       " {'predictions': array([29.161076], dtype=float32)},\n",
       " {'predictions': array([17.697596], dtype=float32)},\n",
       " {'predictions': array([-3.0982437], dtype=float32)},\n",
       " {'predictions': array([19.84588], dtype=float32)},\n",
       " {'predictions': array([14.70575], dtype=float32)},\n",
       " {'predictions': array([5.162443], dtype=float32)},\n",
       " {'predictions': array([1.7172527], dtype=float32)},\n",
       " {'predictions': array([19.282635], dtype=float32)},\n",
       " {'predictions': array([41.79033], dtype=float32)},\n",
       " {'predictions': array([25.750322], dtype=float32)},\n",
       " {'predictions': array([33.782417], dtype=float32)},\n",
       " {'predictions': array([11.057711], dtype=float32)},\n",
       " {'predictions': array([26.487164], dtype=float32)},\n",
       " {'predictions': array([24.722708], dtype=float32)},\n",
       " {'predictions': array([25.012962], dtype=float32)},\n",
       " {'predictions': array([24.009863], dtype=float32)},\n",
       " {'predictions': array([14.671072], dtype=float32)},\n",
       " {'predictions': array([6.502941], dtype=float32)},\n",
       " {'predictions': array([17.340473], dtype=float32)},\n",
       " {'predictions': array([24.861969], dtype=float32)},\n",
       " {'predictions': array([31.524187], dtype=float32)},\n",
       " {'predictions': array([18.539827], dtype=float32)},\n",
       " {'predictions': array([30.38241], dtype=float32)},\n",
       " {'predictions': array([7.6057415], dtype=float32)},\n",
       " {'predictions': array([45.781334], dtype=float32)},\n",
       " {'predictions': array([35.27147], dtype=float32)},\n",
       " {'predictions': array([20.780834], dtype=float32)},\n",
       " {'predictions': array([1.9128094], dtype=float32)},\n",
       " {'predictions': array([31.503508], dtype=float32)},\n",
       " {'predictions': array([12.927464], dtype=float32)},\n",
       " {'predictions': array([29.760406], dtype=float32)},\n",
       " {'predictions': array([33.52781], dtype=float32)},\n",
       " {'predictions': array([-12.5703335], dtype=float32)},\n",
       " {'predictions': array([18.889324], dtype=float32)},\n",
       " {'predictions': array([23.427433], dtype=float32)},\n",
       " {'predictions': array([12.868356], dtype=float32)},\n",
       " {'predictions': array([20.47202], dtype=float32)},\n",
       " {'predictions': array([21.46612], dtype=float32)},\n",
       " {'predictions': array([25.11831], dtype=float32)},\n",
       " {'predictions': array([13.348939], dtype=float32)},\n",
       " {'predictions': array([18.90815], dtype=float32)},\n",
       " {'predictions': array([26.757065], dtype=float32)},\n",
       " {'predictions': array([38.410683], dtype=float32)},\n",
       " {'predictions': array([16.781029], dtype=float32)},\n",
       " {'predictions': array([31.375046], dtype=float32)},\n",
       " {'predictions': array([23.588028], dtype=float32)},\n",
       " {'predictions': array([21.379004], dtype=float32)},\n",
       " {'predictions': array([27.905933], dtype=float32)},\n",
       " {'predictions': array([13.694697], dtype=float32)},\n",
       " {'predictions': array([34.315395], dtype=float32)},\n",
       " {'predictions': array([22.360561], dtype=float32)},\n",
       " {'predictions': array([9.874444], dtype=float32)},\n",
       " {'predictions': array([20.447178], dtype=float32)},\n",
       " {'predictions': array([27.489716], dtype=float32)},\n",
       " {'predictions': array([23.08008], dtype=float32)},\n",
       " {'predictions': array([22.518894], dtype=float32)},\n",
       " {'predictions': array([21.753193], dtype=float32)},\n",
       " {'predictions': array([27.672081], dtype=float32)},\n",
       " {'predictions': array([18.743612], dtype=float32)},\n",
       " {'predictions': array([18.39276], dtype=float32)},\n",
       " {'predictions': array([18.232033], dtype=float32)},\n",
       " {'predictions': array([28.781889], dtype=float32)},\n",
       " {'predictions': array([22.769718], dtype=float32)},\n",
       " {'predictions': array([16.797081], dtype=float32)},\n",
       " {'predictions': array([37.99254], dtype=float32)},\n",
       " {'predictions': array([18.653555], dtype=float32)},\n",
       " {'predictions': array([23.53869], dtype=float32)},\n",
       " {'predictions': array([42.747498], dtype=float32)},\n",
       " {'predictions': array([23.183786], dtype=float32)},\n",
       " {'predictions': array([14.803089], dtype=float32)},\n",
       " {'predictions': array([26.053549], dtype=float32)},\n",
       " {'predictions': array([18.27766], dtype=float32)},\n",
       " {'predictions': array([18.937462], dtype=float32)},\n",
       " {'predictions': array([8.954121], dtype=float32)},\n",
       " {'predictions': array([21.39661], dtype=float32)},\n",
       " {'predictions': array([20.055069], dtype=float32)},\n",
       " {'predictions': array([39.13403], dtype=float32)},\n",
       " {'predictions': array([17.884705], dtype=float32)},\n",
       " {'predictions': array([20.858372], dtype=float32)},\n",
       " {'predictions': array([20.24051], dtype=float32)},\n",
       " {'predictions': array([27.868437], dtype=float32)},\n",
       " {'predictions': array([30.808762], dtype=float32)},\n",
       " {'predictions': array([11.436356], dtype=float32)},\n",
       " {'predictions': array([25.3906], dtype=float32)},\n",
       " {'predictions': array([21.3908], dtype=float32)},\n",
       " {'predictions': array([14.150503], dtype=float32)},\n",
       " {'predictions': array([24.354729], dtype=float32)},\n",
       " {'predictions': array([23.908527], dtype=float32)},\n",
       " {'predictions': array([13.94873], dtype=float32)},\n",
       " {'predictions': array([45.338707], dtype=float32)},\n",
       " {'predictions': array([-6.1124725], dtype=float32)},\n",
       " {'predictions': array([21.871256], dtype=float32)},\n",
       " {'predictions': array([18.80135], dtype=float32)},\n",
       " {'predictions': array([22.099955], dtype=float32)},\n",
       " {'predictions': array([30.287018], dtype=float32)},\n",
       " {'predictions': array([17.989311], dtype=float32)},\n",
       " {'predictions': array([29.461702], dtype=float32)},\n",
       " {'predictions': array([26.010708], dtype=float32)},\n",
       " {'predictions': array([21.077915], dtype=float32)},\n",
       " {'predictions': array([35.772385], dtype=float32)},\n",
       " {'predictions': array([21.321442], dtype=float32)},\n",
       " {'predictions': array([14.099718], dtype=float32)},\n",
       " {'predictions': array([22.852186], dtype=float32)},\n",
       " {'predictions': array([19.490854], dtype=float32)},\n",
       " {'predictions': array([21.836994], dtype=float32)},\n",
       " {'predictions': array([17.556362], dtype=float32)},\n",
       " {'predictions': array([22.853525], dtype=float32)},\n",
       " {'predictions': array([36.971504], dtype=float32)},\n",
       " {'predictions': array([24.454565], dtype=float32)},\n",
       " {'predictions': array([21.61329], dtype=float32)},\n",
       " {'predictions': array([26.712202], dtype=float32)},\n",
       " {'predictions': array([26.508898], dtype=float32)},\n",
       " {'predictions': array([21.747162], dtype=float32)},\n",
       " {'predictions': array([23.533606], dtype=float32)},\n",
       " {'predictions': array([24.588623], dtype=float32)},\n",
       " {'predictions': array([43.87452], dtype=float32)},\n",
       " {'predictions': array([40.532417], dtype=float32)},\n",
       " {'predictions': array([28.758446], dtype=float32)},\n",
       " {'predictions': array([11.246144], dtype=float32)},\n",
       " {'predictions': array([15.42947], dtype=float32)},\n",
       " {'predictions': array([18.004719], dtype=float32)},\n",
       " {'predictions': array([22.946342], dtype=float32)},\n",
       " {'predictions': array([15.3929615], dtype=float32)},\n",
       " {'predictions': array([2.4639397], dtype=float32)},\n",
       " {'predictions': array([25.941534], dtype=float32)},\n",
       " {'predictions': array([33.48319], dtype=float32)},\n",
       " {'predictions': array([23.589254], dtype=float32)},\n",
       " {'predictions': array([19.625973], dtype=float32)},\n",
       " {'predictions': array([16.279964], dtype=float32)},\n",
       " {'predictions': array([24.195272], dtype=float32)},\n",
       " {'predictions': array([38.044937], dtype=float32)},\n",
       " {'predictions': array([23.286442], dtype=float32)},\n",
       " {'predictions': array([32.59817], dtype=float32)},\n",
       " {'predictions': array([19.24921], dtype=float32)},\n",
       " {'predictions': array([22.644403], dtype=float32)},\n",
       " {'predictions': array([31.671337], dtype=float32)},\n",
       " {'predictions': array([12.583172], dtype=float32)},\n",
       " {'predictions': array([33.033756], dtype=float32)}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets calculate the predicted value\n",
    "list(linear_model.predict(input_fn = eval_input_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50d6cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = linear_model.predict(input_fn=eval_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c8161a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\KUSHAL~1\\AppData\\Local\\Temp\\tmpbetxdlj8\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "pred = list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cec5a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\KUSHAL~1\\AppData\\Local\\Temp\\tmpbetxdlj8\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "# Plot Predicted Values\n",
    "predicted_vals = []\n",
    "\n",
    "for pred in linear_model.predict(input_fn=eval_input_func):\n",
    "    predicted_vals.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "feedfbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 152)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_vals), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5bf766df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([40.68284], dtype=float32), array([31.554699], dtype=float32), array([28.544626], dtype=float32), array([4.8447056], dtype=float32), array([35.71012], dtype=float32), array([2.7373486], dtype=float32), array([27.648514], dtype=float32), array([31.919151], dtype=float32), array([28.238222], dtype=float32), array([24.0307], dtype=float32), array([34.662785], dtype=float32), array([22.980503], dtype=float32), array([24.163229], dtype=float32), array([35.480255], dtype=float32), array([29.161076], dtype=float32), array([17.697596], dtype=float32), array([-3.0982437], dtype=float32), array([19.84588], dtype=float32), array([14.70575], dtype=float32), array([5.162443], dtype=float32), array([1.7172527], dtype=float32), array([19.282635], dtype=float32), array([41.79033], dtype=float32), array([25.750322], dtype=float32), array([33.782417], dtype=float32), array([11.057711], dtype=float32), array([26.487164], dtype=float32), array([24.722708], dtype=float32), array([25.012962], dtype=float32), array([24.009863], dtype=float32), array([14.671072], dtype=float32), array([6.502941], dtype=float32), array([17.340473], dtype=float32), array([24.861969], dtype=float32), array([31.524187], dtype=float32), array([18.539827], dtype=float32), array([30.38241], dtype=float32), array([7.6057415], dtype=float32), array([45.781334], dtype=float32), array([35.27147], dtype=float32), array([20.780834], dtype=float32), array([1.9128094], dtype=float32), array([31.503508], dtype=float32), array([12.927464], dtype=float32), array([29.760406], dtype=float32), array([33.52781], dtype=float32), array([-12.5703335], dtype=float32), array([18.889324], dtype=float32), array([23.427433], dtype=float32), array([12.868356], dtype=float32), array([20.47202], dtype=float32), array([21.46612], dtype=float32), array([25.11831], dtype=float32), array([13.348939], dtype=float32), array([18.90815], dtype=float32), array([26.757065], dtype=float32), array([38.410683], dtype=float32), array([16.781029], dtype=float32), array([31.375046], dtype=float32), array([23.588028], dtype=float32), array([21.379004], dtype=float32), array([27.905933], dtype=float32), array([13.694697], dtype=float32), array([34.315395], dtype=float32), array([22.360561], dtype=float32), array([9.874444], dtype=float32), array([20.447178], dtype=float32), array([27.489716], dtype=float32), array([23.08008], dtype=float32), array([22.518894], dtype=float32), array([21.753193], dtype=float32), array([27.672081], dtype=float32), array([18.743612], dtype=float32), array([18.39276], dtype=float32), array([18.232033], dtype=float32), array([28.781889], dtype=float32), array([22.769718], dtype=float32), array([16.797081], dtype=float32), array([37.99254], dtype=float32), array([18.653555], dtype=float32), array([23.53869], dtype=float32), array([42.747498], dtype=float32), array([23.183786], dtype=float32), array([14.803089], dtype=float32), array([26.053549], dtype=float32), array([18.27766], dtype=float32), array([18.937462], dtype=float32), array([8.954121], dtype=float32), array([21.39661], dtype=float32), array([20.055069], dtype=float32), array([39.13403], dtype=float32), array([17.884705], dtype=float32), array([20.858372], dtype=float32), array([20.24051], dtype=float32), array([27.868437], dtype=float32), array([30.808762], dtype=float32), array([11.436356], dtype=float32), array([25.3906], dtype=float32), array([21.3908], dtype=float32), array([14.150503], dtype=float32), array([24.354729], dtype=float32), array([23.908527], dtype=float32), array([13.94873], dtype=float32), array([45.338707], dtype=float32), array([-6.1124725], dtype=float32), array([21.871256], dtype=float32), array([18.80135], dtype=float32), array([22.099955], dtype=float32), array([30.287018], dtype=float32), array([17.989311], dtype=float32), array([29.461702], dtype=float32), array([26.010708], dtype=float32), array([21.077915], dtype=float32), array([35.772385], dtype=float32), array([21.321442], dtype=float32), array([14.099718], dtype=float32), array([22.852186], dtype=float32), array([19.490854], dtype=float32), array([21.836994], dtype=float32), array([17.556362], dtype=float32), array([22.853525], dtype=float32), array([36.971504], dtype=float32), array([24.454565], dtype=float32), array([21.61329], dtype=float32), array([26.712202], dtype=float32), array([26.508898], dtype=float32), array([21.747162], dtype=float32), array([23.533606], dtype=float32), array([24.588623], dtype=float32), array([43.87452], dtype=float32), array([40.532417], dtype=float32), array([28.758446], dtype=float32), array([11.246144], dtype=float32), array([15.42947], dtype=float32), array([18.004719], dtype=float32), array([22.946342], dtype=float32), array([15.3929615], dtype=float32), array([2.4639397], dtype=float32), array([25.941534], dtype=float32), array([33.48319], dtype=float32), array([23.589254], dtype=float32), array([19.625973], dtype=float32), array([16.279964], dtype=float32), array([24.195272], dtype=float32), array([38.044937], dtype=float32), array([23.286442], dtype=float32), array([32.59817], dtype=float32), array([19.24921], dtype=float32), array([22.644403], dtype=float32), array([31.671337], dtype=float32), array([12.583172], dtype=float32), array([33.033756], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a568a2b",
   "metadata": {},
   "source": [
    "# Calculate MeanSquared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb88d4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error [Linear Regressor] :  37.339186560203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(predicted_vals, y_test)\n",
    "\n",
    "print(\"Mean Squared Error [Linear Regressor] : \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65cc261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
